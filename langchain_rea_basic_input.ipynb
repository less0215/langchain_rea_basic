{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install beautifulsoup4 langchain langchain-text-splitters langchain-community faiss-cpu langchain-core langchain-openai openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 필요한 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"api_key\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"project_name\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WebBaseLoader 이용해서 웹페이지 내용 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수 : 1\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    # 소괄호 안에 ','를 넣는 이유는 '단일 요소만 있다'는 걸 알리기 위해서.\n",
    "    web_paths = (\"https://n.news.naver.com/article/437/0000378416\",),\n",
    "    # 'bs_kwargs'는 BeautifulSoup 키워드라는 뜻\n",
    "    # SoupStrainer() 첫번째 인자는 문자열만 넣어도 태그로 인식\n",
    "    bs_kwargs = dict(\n",
    "        parse_only= bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]}\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수 : {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter 이용해서 문서 내용 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorstore에 쪼갠 문서 담기 (임배딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS는 페이스북에서 만든 백터 데이터베이스 라이브러리\n",
    "# FAISS (Facebook AI Similarity Search)\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate 이용해서 프롬프트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
    "검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\n",
    "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요. Don't narrate the answer, just answer the question. Let's think step-by-step.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "\n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### llm 모델 생성 후 기본체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# RunnablePassthrough에는 rag_chain이 실행 될 때 들어오는 질문이 들어간다.\n",
    "# 질문이 들어 오면, retriever가 질문에 적절한 내용은 쪼개 놓은 문서에서 찾는다.\n",
    "# 찾은 내용을 context에 넣는다.\n",
    "# context, question 내용이 적용된 prompt는 llm으로 전달한다.\n",
    "# llm은 StrOutputParser()에 의해 질문에 대한 답변을 생성한다.\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실시간 출력(스트리밍 출력) 하기 위한 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamChain:\n",
    "    # 자동으로 생성되는 내장함수이지만, 일부러 만든 이유는 chain을 받기 위해서.\n",
    "    def __init__(self, chain):\n",
    "        self.chain = chain\n",
    "\n",
    "    def stream(self, query):\n",
    "        # 사용자 질문이 'query'로 들어간다. \n",
    "        # self.chain(기본체인)에 따라 답변이 생성되고, 해당 답변은 'response'에 담긴다.\n",
    "        response = self.chain.stream(query)\n",
    "        # 아무 값이 없는 빈 공간을 만들어준다. 해당 공간은 답변이 담길 공간이다.\n",
    "        complete_response = \"\"\n",
    "        # 생성된 답변을 반복문을 이용해 형태소 단위로 쪼개어 준다.\n",
    "        for token in response:\n",
    "            # end=\"\"는 줄바꿈 없이 계속 실행하라는 코드다.\n",
    "            # flush=True는 '실시간 출력해라'라는 의미를 가진 코드다.\n",
    "            print(token, end=\"\", flush=True)\n",
    "            # 실시간으로 출력된 형태소를 합쳐주는 역할을 한다.\n",
    "            complete_response += token\n",
    "        return complete_response\n",
    "\n",
    "chain = StreamChain(rag_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 체인과 함수 이용해 답변 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [langsmith 이용해서 답변 출력 과정 보기](https://smith.langchain.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부영그룹의 출산 장려 정책은 2021년 이후 태어난 직원 자녀에게 1억원을 지원하는 것입니다. 이 정책은 총 70억원 규모로, 연년생이나 쌍둥이 자녀가 있을 경우 총 2억원을 받을 수 있습니다. 또한, 셋째 자녀를 낳는 경우에는 국민주택을 제공하겠다는 계획도 밝혔습니다. 이 외에도 출산장려금에 대한 세금 면세를 정부에 제안하기도 했습니다."
     ]
    }
   ],
   "source": [
    "answer = chain.stream(\"부영그룹의 출산 장려 정책에 대해 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다."
     ]
    }
   ],
   "source": [
    "# rag와 프롬프트를 이용했기 때문에 할루시네이션이 발생하지 않았다\n",
    "answer = chain.stream(\"부영그룹의 임직원 숫자는 몇명인가요?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
